apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    role: server
  name: {{ template "triton-inference-server.fullname" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ template "triton-inference-server.name" . }}
    chart: {{ template "triton-inference-server.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
spec:
  replicas: {{ .Values.autoscaling.minReplicas }}
  selector:
    matchLabels:
      app: {{ template "triton-inference-server.name" . }}
      release: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app: {{ template "triton-inference-server.name" . }}
        release: {{ .Release.Name }}
    spec:
      imagePullSecrets:
        - name: ngc-secret
      volumes:
        - name: {{ template "triton-inference-server.fullname" . }}
          persistentVolumeClaim:
            claimName: {{ template "triton-inference-server.fullname" . }}
      containers:
        - name: {{ .Chart.Name }}
          image: "{{ .Values.image.imageName }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}

        {{- with .Values.image.resources }}
          resources:
          {{- toYaml . | nindent 12 }}
        {{- end}}
          volumeMounts:
            - mountPath: /opt/tritonserver/model_repository
              name: {{ template "triton-inference-server.fullname" . }}
          args: ["tritonserver", "--allow-metrics=true", "--allow-gpu-metrics=true", "--model-control-mode=poll", "--repository-poll-secs=10", "--model-repository=/opt/tritonserver/model_repository/"]
          ports:
            - containerPort: 8000
              name: http
            - containerPort: 8001
              name: grpc
            - containerPort: 8002
              name: metrics
          livenessProbe:
            httpGet:
              path: /v2/health/live
              port: http
          readinessProbe:
            initialDelaySeconds: 5
            periodSeconds: 5
            httpGet:
              path: /v2/health/ready
              port: http
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    role: client
  name: {{ template "triton-inference-server.fullname" . }}-client
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ template "triton-inference-server.name" . }}
    chart: {{ template "triton-inference-server.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {{ template "triton-inference-server.name" . }}
      release: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app: {{ template "triton-inference-server.name" . }}
        release: {{ .Release.Name }}
    spec:
      volumes:
        - name: {{ template "triton-inference-server.fullname" . }}
          persistentVolumeClaim:
            claimName: {{ template "triton-inference-server.fullname" . }}
      imagePullSecrets:
        - name: ngc-secret
      containers:
        - name: {{ .Chart.Name }}-client
          image: "{{ .Values.devimage.imageName }}"
          imagePullPolicy: {{ .Values.devimage.pullPolicy }}
        {{- with .Values.devimage.resources }}
          resources:
          {{- toYaml . | nindent 12 }}
        {{- end}}
          volumeMounts:
            - mountPath: /opt/tritonserver/model_repository
              name: {{ template "triton-inference-server.fullname" . }}
          args: ["sleep", "infinity"]
